<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BREATH Demo - Multimodal Music Generation</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <!-- 导航栏 -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-logo">
                <i class="fas fa-music"></i>
                <span>BREATH Demo</span>
            </div>
            <ul class="nav-menu">
                <li><a href="#home">Home</a></li>
                <li><a href="#demo">Audio Demo</a></li>
                <li><a href="#agent">Parameters</a></li>
                <li><a href="#about">About</a></li>
            </ul>
            <div class="hamburger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
    </nav>

    <!-- 主页横幅 -->
    <section id="home" class="hero">
        <div class="hero-container">
            <div class="hero-content">
                <h1 class="hero-title">BREATH Demo</h1>
                <p class="hero-subtitle">Multimodal Music Generation System</p>
                <div class="abstract-section">
                    <h3>ABSTRACT</h3>
                    <p class="abstract-text">
                        We present a multimodal system for personalized music generation that integrates physiological sensing, LLM-based reasoning, and controllable audio synthesis. A millimeter-wave radar sensor non-invasively captures heart rate and respiration rate. These physiological signals, combined with environmental state, are interpreted by a reasoning agent to infer symbolic musical descriptors, such as tempo, mood intensity, and traditional Chinese pentatonic modes, which are then expressed as structured prompts to guide a diffusion-based audio model in synthesizing expressive melodies. The system emphasizes cultural grounding through tonal embeddings and enables adaptive, embodied music interaction. To evaluate the system, we adopt a research-creation methodology combining case studies, expert feedback, and targeted control experiments. Results show that physiological variations can modulate musical features in meaningful ways, and tonal conditioning enhances alignment with intended modal characteristics. Expert users reported that the system affords intuitive, culturally resonant musical responses and highlighted its potential for therapeutic and interactive applications. This work demonstrates a novel bio-musical feedback loop linking radar-based sensing, prompt reasoning, and generative audio modeling.
                    </p>
                </div>
                <div class="hero-buttons">
                    <a href="#demo" class="btn btn-primary">Audio Demo</a>
                    <a href="#agent" class="btn btn-secondary">Parameters</a>
                </div>
            </div>
            <div class="hero-visual">
                <div class="music-visualizer">
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                </div>
            </div>
        </div>
    </section>

    <!-- 音频Demo区域 -->
    <section id="demo" class="demo-section">
        <div class="container">
            <h2 class="section-title">Audio Demo</h2>
            <p class="section-subtitle">Physiological changes modulate the mode and mood of generated music</p>
            
            <div class="audio-demos" id="audio-demos">
                <!-- 动态加载的音频demo将在这里显示 -->
            </div>

            <div class="demo-controls">
                <button class="btn btn-secondary" onclick="downloadAll()">
                    <i class="fas fa-download"></i>
                    Download All
                </button>
            </div>
        </div>
    </section>

    <!-- Agent参数表区域 -->
    <section id="agent" class="agent-section">
        <div class="container">
            <h2 class="section-title">System Parameters</h2>
            <p class="section-subtitle">Core parameters for multimodal music generation</p>
            
            <div class="agent-parameters" id="agent-parameters">
                <div class="parameter-section">
                    <h3><i class="fas fa-database"></i> L0: Events - 使用记录</h3>
                    <div class="parameter-table-container">
                        <table class="parameter-table">
                            <thead>
                                <tr>
                                    <th>字段</th>
                                    <th>类型</th>
                                    <th>示例</th>
                                    <th>说明 (对应论文)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><strong>event_id</strong></td>
                                    <td>string</td>
                                    <td><code>evt_20250626_2230_001</code></td>
                                    <td>时间步ID (Timestamp ID)</td>
                                </tr>
                                <tr>
                                    <td><strong>user_id</strong></td>
                                    <td>string</td>
                                    <td><code>xiaomei</code></td>
                                    <td>用户 (User)</td>
                                </tr>
                                <tr>
                                    <td><strong>time_local</strong></td>
                                    <td>datetime</td>
                                    <td><code>2025-06-26T22:30:00+08:00</code></td>
                                    <td>时序 (可由LLM 推断"late evening"但不落库)</td>
                                </tr>
                                <tr>
                                    <td><strong>scene</strong></td>
                                    <td>enum</td>
                                    <td><code>sleep / work / exercise / relax</code></td>
                                    <td>场景标签 (Scene tag)</td>
                                </tr>
                                <tr>
                                    <td><strong>inputs.hr_bpm</strong></td>
                                    <td>int</td>
                                    <td><code>72</code></td>
                                    <td>心率数值 (Heart rate value)</td>
                                </tr>
                                <tr>
                                    <td><strong>inputs.resp_rate</strong></td>
                                    <td>int</td>
                                    <td><code>14</code></td>
                                    <td>呼吸数值(次/分) (Respiration rate value)</td>
                                </tr>
                                <tr>
                                    <td><strong>inputs.temperature_c?</strong></td>
                                    <td>int</td>
                                    <td><code>25</code></td>
                                    <td>可选环境温度(数值) (Optional ambient temperature)</td>
                                </tr>
                                <tr>
                                    <td><strong>inputs.user_context?</strong></td>
                                    <td>string</td>
                                    <td><code>"play calm music"</code></td>
                                    <td>可选用户意图 (Optional user intent)</td>
                                </tr>
                                <tr>
                                    <td><strong>inputs.prev_instruments?</strong></td>
                                    <td>string[]</td>
                                    <td><code>["pads","strings"]</code></td>
                                    <td>上一步器乐 (Previous instruments)</td>
                                </tr>
                                <tr>
                                    <td><strong>inputs.prev_mode?</strong></td>
                                    <td>enum</td>
                                    <td><code>Gong/Shang/Jue/Zhi/Yu</code></td>
                                    <td>上一步调式 (Previous mode)</td>
                                </tr>
                                <tr>
                                    <td><strong>outputs.intent</strong></td>
                                    <td>enum</td>
                                    <td><code>stabilize/stimulate/transition</code></td>
                                    <td>决策(论文步骤2) (Decision - Paper Step 2)</td>
                                </tr>
                                <tr>
                                    <td><strong>outputs.tempo</strong></td>
                                    <td>int | enum</td>
                                    <td><code>66</code> 或 <code>"moderate"</code></td>
                                    <td>四参之一 (One of the four parameters)</td>
                                </tr>
                                <tr>
                                    <td><strong>outputs.style</strong></td>
                                    <td>string</td>
                                    <td><code>"ambient_relaxed_traditional_chinese"</code></td>
                                    <td>四参之一 (One of the four parameters)</td>
                                </tr>
                                <tr>
                                    <td><strong>outputs.instruments</strong></td>
                                    <td>string[]</td>
                                    <td><code>["pads", "strings"]</code></td>
                                    <td>四参之一 (One of the four parameters)</td>
                                </tr>
                                <tr>
                                    <td><strong>outputs.mode</strong></td>
                                    <td>enum</td>
                                    <td><code>Yu</code></td>
                                    <td>四参之一 (宫商角徵羽) (One of the four parameters)</td>
                                </tr>
                                <tr>
                                    <td><strong>feedback.thumb?</strong></td>
                                    <td>enum</td>
                                    <td>👍/👎</td>
                                    <td>可选反馈 (Optional feedback)</td>
                                </tr>
                                <tr>
                                    <td><strong>feedback.listen_secs?</strong></td>
                                    <td>int</td>
                                    <td><code>2100</code></td>
                                    <td>可选聆听时长 (Optional listening duration)</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- 关于区域 -->
    <section id="about" class="about-section">
        <div class="container">
            <h2 class="section-title">About BREATH Demo</h2>
            <div class="about-content">
                <div class="about-text">
                    <p>
                        BREATH is a multimodal music-generation system that turns millimetre-wave radar heart-rate & respiration signals into Chinese-pentatonic audio in real time.
                    </p>
                    <p>
                        A radar front-end captures HR/RR; an LLM agent maps these body states to musical parameters (tempo, genre, instrumentation, Gong–Yu mode); a latent-diffusion transformer synthesises 44.1 kHz stereo.
                    </p>
                    <p>
                        The clips on this page illustrate how physiological changes modulate the mode and mood of the generated music.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- 页脚 -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>BREATH Demo</h3>
                    <p>Multimodal Music Generation System</p>
                </div>
                <div class="footer-section">
                    <h4>Navigation</h4>
                    <ul>
                        <li><a href="#demo">Audio Demo</a></li>
                        <li><a href="#agent">Parameters</a></li>
                        <li><a href="#about">About</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 BREATH Demo. Research demonstration.</p>
            </div>
        </div>
    </footer>

    <script src="audio-config.js"></script>
    <script src="script.js"></script>
</body>
</html>
